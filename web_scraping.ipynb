{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Wikipedia Main page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_scrape(url):\n",
    "    \"\"\"This function takes in the main page URL of Wikipedia and scrapes the Header tags, stores them in a csv file\"\"\"\n",
    "    #Requesting html\n",
    "    source = requests.get(url).text\n",
    "    #Pasing the html\n",
    "    soup = bs(source, 'lxml')\n",
    "    #creating CSV\n",
    "    csv_file = open('wiki_headers.csv', 'w')\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(['Sr', 'Header_Tags'])\n",
    "    #Extracting header tags\n",
    "    n=1\n",
    "    for i in soup.find_all('h2', class_ = 'mp-h2'):\n",
    "        csv_writer.writerow([n, i.text])\n",
    "        n=n+1\n",
    "    csv_file.close()\n",
    "    df=pd.read_csv('wiki_headers.csv',encoding = 'unicode_escape')\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sr                    Header_Tags\n",
      "0   1  From today's featured article\n",
      "1   2               Did you know ...\n",
      "2   3                    In the news\n",
      "3   4                    On this day\n",
      "4   5       Today's featured picture\n",
      "5   6       Other areas of Wikipedia\n",
      "6   7    Wikipedia's sister projects\n",
      "7   8            Wikipedia languages\n"
     ]
    }
   ],
   "source": [
    "wiki_scrape('https://en.wikipedia.org/wiki/Main_Page')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) IMDB top 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_all(url):\n",
    "    \"\"\"This function will extract top 100 movies in descending order as listed on IMDB, you must pass page 1 URL\"\"\"\n",
    "    source1 = requests.get(url).text\n",
    "    soup = bs(source1, 'lxml')\n",
    "    csv_file = open('imdb_top100.csv', 'w')\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(['Name', 'Year', 'IMDB Ratings'])\n",
    "    for i in soup.find_all('div', class_ = 'lister-item-content'):\n",
    "        name = i.h3.a.text\n",
    "        year = i.find('span', class_='lister-item-year text-muted unbold').text[1:5]\n",
    "        ratings = i.find('div', class_='inline-block ratings-imdb-rating').strong.text\n",
    "        writer.writerow([name, year, ratings])\n",
    "    url2 = url+'&start=51&ref_=adv_nxt'\n",
    "    source2 = requests.get(url2).text\n",
    "    soup = bs(source2, 'lxml')\n",
    "    for i in soup.find_all('div', class_ = 'lister-item-content'):\n",
    "        name = i.h3.a.text\n",
    "        year = i.find('span', class_='lister-item-year text-muted unbold').text[1:5]\n",
    "        ratings = i.find('div', class_='inline-block ratings-imdb-rating').strong.text\n",
    "        writer.writerow([name, year, ratings])\n",
    "    csv_file.close()\n",
    "    df = pd.read_csv('imdb_top100.csv',encoding = 'unicode_escape')\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Name  Year  IMDB Ratings\n",
      "0            The Shawshank Redemption  1994           9.3\n",
      "1                       The Godfather  1972           9.2\n",
      "2                     The Dark Knight  2008           9.0\n",
      "3              The Godfather: Part II  1974           9.0\n",
      "4                        12 Angry Men  1957           9.0\n",
      "..                                ...   ...           ...\n",
      "95                            Vertigo  1958           8.3\n",
      "96                Singin' in the Rain  1952           8.3\n",
      "97                Ladri di biciclette  1948           8.3\n",
      "98                       Citizen Kane  1941           8.3\n",
      "99  M - Eine Stadt sucht einen Mörder  1931           8.3\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "imdb_all('https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB Indian movies top 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_indian(url):\n",
    "    source = requests.get(url).text\n",
    "    soup = bs(source, 'lxml')\n",
    "    csv_file = open(\"top_100_indian.csv\", 'w')\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(['Name', 'Year', 'Ratings', 'Votes'])\n",
    "    n=0\n",
    "    for i,j,k in zip(soup.find_all('td', class_ = 'titleColumn'),soup.find_all('td', class_='ratingColumn imdbRating'),soup.find_all('td', class_='ratingColumn imdbRating')):\n",
    "        try:\n",
    "            name=i.text.strip()[3:].strip()[:-7]\n",
    "        except:\n",
    "            name = None\n",
    "        try:\n",
    "            year=i.text[-6:-2]\n",
    "        except:\n",
    "            year = None\n",
    "        try:\n",
    "            rating = j.text.strip()\n",
    "        except:\n",
    "            rating = None\n",
    "        try:\n",
    "            votes = k.strong['title']\n",
    "            votes = re.findall('\\d+', votes[3:])\n",
    "            votes = votes[0]+votes[1]\n",
    "        except:\n",
    "            votes = None\n",
    "        writer.writerow([name, year, rating, votes])\n",
    "        if n==99:\n",
    "            break\n",
    "        n=n+1\n",
    "    csv_file.close()\n",
    "    df = pd.read_csv('top_100_indian.csv', encoding = 'unicode_escape')\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Name  Year  Ratings  Votes\n",
      "0     Pather Panchali  1955      8.5  23359\n",
      "1            Gol Maal  1979      8.5  17923\n",
      "2            Ratsasan  2018      8.5  23671\n",
      "3             Nayakan  1987      8.5  16142\n",
      "4          Anbe Sivam  2003      8.5  16626\n",
      "..                ...   ...      ...    ...\n",
      "95         Bommarillu  2006      8.0   8542\n",
      "96              Lucia  2013      8.0  11470\n",
      "97            Maqbool  2003      8.0   9499\n",
      "98             Bombay  1995      8.0  11278\n",
      "99  .\\r\\n      Omkara  2006      8.0  19138\n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "imdb_indian(\"https://www.imdb.com/india/top-rated-indian-movies/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Book Page scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function doesn't scrape 'https://bookpage.com/', but 'https://bookpage.com/reviews'\n",
    "def bookpage(url):\n",
    "    \"\"\"This function will scrape 5 books from bookpage.com/reviews, and store the book name, author, genre and summary\n",
    "    in a csv file\"\"\"\n",
    "    source = requests.get(url).text\n",
    "    soup = bs(source, 'lxml')\n",
    "    csv_file = open(\"books.csv\", 'w', encoding = 'utf-8')\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(['Book Name', 'Author', 'Genre', 'Summary'])\n",
    "    n=1\n",
    "    for i in soup.find_all('div', class_='flex-article-content'):\n",
    "        try:\n",
    "            book = i.a.text\n",
    "            print(book)\n",
    "        except:\n",
    "            book = None\n",
    "        try:\n",
    "            author = i.find('p', class_='sans bold').text.strip()\n",
    "            print(author)\n",
    "        except:\n",
    "            author = None\n",
    "        try:\n",
    "            summary = [a.text.strip() for a in i.find_all('p') if len(a.text.strip())>70]\n",
    "            summary = summary[0]\n",
    "            print(summary)\n",
    "        except:\n",
    "            summary = None\n",
    "        try:\n",
    "            genre = i.find('p', class_ = 'genre-links hidden-phone').text.replace('\\n', '')\n",
    "            print(genre)\n",
    "        except:\n",
    "            genre = None\n",
    "        writer.writerow([book, author, genre, summary])  \n",
    "        if n==5:\n",
    "            break\n",
    "        n=n+1\n",
    "    csv_file.close()\n",
    "    df = pd.read_csv('books.csv', encoding = 'unicode-escape')\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Children's Train\n",
      "Viola Ardone, Clarissa Botsford\n",
      "The displacement of children is a vexing problem in international and national politics. Italian author Viola Ardone’s novel explores issues surrounding children who are separated from their parents, but in this case, the families willingly send their youngsters away to live in the care of...\n",
      "Fiction / Historical Fiction\n",
      "The Lion of Mars\n",
      "Jennifer L. Holm\n",
      "In the year 2091, millions of miles away from Earth, 11-year-old Bell and a handful of other kids are growing up on Mars. Sent there as orphaned infants, they have never known another life, another home or another family. Along with several adults, they make up the American settlement, where...\n",
      "Children's / Middle Grade\n",
      "What Could Be Saved\n",
      "Liese O'Halloran Schwarz\n",
      "At the heart of family novels there’s often a secret, and how that secret plays out in family dynamics forms the heart of the story. Liese O’Halloran Schwarz’s third novel is no exception, with several secrets reverberating from the past.\n",
      "Fiction / Family Saga\n",
      "Aftershocks\n",
      "Nadia Owusu\n",
      "Aftershocks is an intimate work told in an imaginative style, with the events that shaped its author rippling throughout her nonlinear story.\n",
      "Nonfiction / Biography & Memoir / Memoir\n",
      " ★ Black Buck\n",
      "Mateo Askaripour\n",
      "In his debut novel, Mateo Askaripour offers a witty yet thrilling examination of the complexities of race in corporate America.\n",
      "Fiction / Satirical Fiction\n",
      "              Book Name                           Author  \\\n",
      "0  The Children's Train  Viola Ardone, Clarissa Botsford   \n",
      "1      The Lion of Mars                 Jennifer L. Holm   \n",
      "2   What Could Be Saved         Liese O'Halloran Schwarz   \n",
      "3           Aftershocks                      Nadia Owusu   \n",
      "4        â",
      " Black Buck                 Mateo Askaripour   \n",
      "\n",
      "                                      Genre  \\\n",
      "0              Fiction / Historical Fiction   \n",
      "1                 Children's / Middle Grade   \n",
      "2                     Fiction / Family Saga   \n",
      "3  Nonfiction / Biography & Memoir / Memoir   \n",
      "4               Fiction / Satirical Fiction   \n",
      "\n",
      "                                             Summary  \n",
      "0  The displacement of children is a vexing probl...  \n",
      "1  In the year 2091, millions of miles away from ...  \n",
      "2  At the heart of family novels thereâs often ...  \n",
      "3  Aftershocks is an intimate work told in an ima...  \n",
      "4  In his debut novel, Mateo Askaripour offers a ...  \n"
     ]
    }
   ],
   "source": [
    "bookpage('https://bookpage.com/reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) ICC men's ODI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icc_mens(url):\n",
    "    #Part 1: Team Rankings\n",
    "    source=requests.get(url).text\n",
    "    soup=bs(source, 'lxml')\n",
    "    csv_file = open('team_odi.csv', 'w')\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(['Rank','Team', 'Matches', 'Points', 'Rating'])\n",
    "    tbody=soup.find('tbody')\n",
    "    a=0\n",
    "    m=0\n",
    "    n=1\n",
    "    k=0\n",
    "    rank=1\n",
    "    for i in tbody.find_all('span', class_='u-hide-phablet'):\n",
    "        team = i.text\n",
    "        if a == 0:\n",
    "            match = tbody.find('td', class_='rankings-block__banner--matches').text\n",
    "            points = tbody.find('td', class_='rankings-block__banner--points').text\n",
    "            rating = tbody.find('td', class_='rankings-block__banner--rating u-text-right').text.replace('\\n', '').strip()\n",
    "            writer.writerow([rank, team, match, points, rating])\n",
    "            rank=rank+1\n",
    "            a=a+1\n",
    "            continue\n",
    "        match = tbody.find_all('td',class_=\"table-body__cell u-center-text\")[m].text\n",
    "        points = tbody.find_all('td',class_=\"table-body__cell u-center-text\")[n].text\n",
    "        m=m+2\n",
    "        n=n+2\n",
    "        rating = tbody.find_all('td', class_=\"table-body__cell u-text-right rating\")[k].text\n",
    "        writer.writerow([rank,team, match, points, rating])\n",
    "        k=k+1\n",
    "        rank=rank+1\n",
    "        if k == 9:\n",
    "            break\n",
    "    csv_file.close()\n",
    "    df = pd.read_csv('team_odi.csv', encoding = 'unicode-escape')\n",
    "    print(df)\n",
    "    #Part 2: ODI batsmen ranking\n",
    "    source = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting').text\n",
    "    soup = bs(source, 'lxml')\n",
    "    csv_file = open('batsmen.csv', 'w')\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(['Rank','Player','Team', 'Rating'])\n",
    "    table = soup.find('table', class_ = 'table rankings-table')\n",
    "    player = table.find('div', class_=\"rankings-block__banner--name-large\").text\n",
    "    team = table.find('div' ,class_=\"rankings-block__banner--nationality\").text.strip()\n",
    "    rating = table.find('div', class_=\"rankings-block__banner--rating\").text\n",
    "    rank = 1\n",
    "    writer.writerow([rank, player, team, rating])\n",
    "    for i, j, k  in zip(table.find_all('td', class_=\"table-body__cell rankings-table__name name\"),\n",
    "                    table.find_all('span', class_=\"table-body__logo-text\"),\n",
    "                    table.find_all('td' ,class_=\"table-body__cell rating\")):\n",
    "        player = i.text.strip()\n",
    "        team = j.text\n",
    "        rating = k.text\n",
    "        rank = rank+1\n",
    "        writer.writerow([rank, player, team, rating])\n",
    "        if rank == 10:\n",
    "            break\n",
    "    csv_file.close()\n",
    "    df=pd.read_csv('batsmen.csv', encoding = 'unicode-escape')\n",
    "    print(df)\n",
    "    #Part 3: ODI bowler ranking\n",
    "    source = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling').text\n",
    "    soup = bs(source, 'lxml')\n",
    "    table = soup.find('table', class_ = 'table rankings-table')\n",
    "    csv_file = open('bowler.csv', 'w')\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(['Rank','Player','Team', 'Rating'])\n",
    "    player = table.find('div', class_=\"rankings-block__banner--name-large\").text\n",
    "    team = table.find('div' ,class_=\"rankings-block__banner--nationality\").text.strip()\n",
    "    rating = table.find('div', class_=\"rankings-block__banner--rating\").text\n",
    "    rank = 1\n",
    "    writer.writerow([rank, player, team, rating])\n",
    "    for i, j, k  in zip(table.find_all('td', class_=\"table-body__cell rankings-table__name name\"),\n",
    "                    table.find_all('span', class_=\"table-body__logo-text\"),\n",
    "                    table.find_all('td' ,class_=\"table-body__cell rating\")):\n",
    "        player = i.text.strip()\n",
    "        team = j.text\n",
    "        rating = k.text\n",
    "        rank = rank+1\n",
    "        writer.writerow([rank, player, team, rating])\n",
    "        if rank == 10:\n",
    "            break\n",
    "    csv_file.close()\n",
    "    df=pd.read_csv('bowler.csv', encoding = 'unicode-escape')\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank          Team  Matches Points  Rating\n",
      "0     1       England       44  5,405     123\n",
      "1     2         India       52  6,102     117\n",
      "2     3   New Zealand       32  3,716     116\n",
      "3     4     Australia       39  4,344     111\n",
      "4     5  South Africa       31  3,345     108\n",
      "5     6      Pakistan       35  3,490     100\n",
      "6     7    Bangladesh       34  2,989      88\n",
      "7     8     Sri Lanka       39  3,297      85\n",
      "8     9   West Indies       43  3,285      76\n",
      "9    10   Afghanistan       28  1,549      55\n",
      "   Rank               Player Team  Rating\n",
      "0     1          Virat Kohli  IND     870\n",
      "1     2         Rohit Sharma  IND     842\n",
      "2     3           Babar Azam  PAK     837\n",
      "3     4          Ross Taylor   NZ     818\n",
      "4     5          Aaron Finch  AUS     791\n",
      "5     6  Francois du Plessis   SA     790\n",
      "6     7         David Warner  AUS     773\n",
      "7     8      Kane Williamson   NZ     765\n",
      "8     9      Quinton de Kock   SA     755\n",
      "9    10       Jonny Bairstow  ENG     754\n",
      "   Rank            Player Team  Rating\n",
      "0     1       Trent Boult   NZ     722\n",
      "1     2  Mujeeb Ur Rahman  AFG     701\n",
      "2     3    Jasprit Bumrah  IND     700\n",
      "3     4      Chris Woakes  ENG     675\n",
      "4     5     Kagiso Rabada   SA     665\n",
      "5     6    Josh Hazlewood  AUS     660\n",
      "6     7     Mohammad Amir  PAK     647\n",
      "7     8       Pat Cummins  AUS     646\n",
      "8     9        Matt Henry   NZ     641\n",
      "9    10      Jofra Archer  ENG     637\n"
     ]
    }
   ],
   "source": [
    "icc_mens('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) ICC Women's ODI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icc_women(url):\n",
    "    source = requests.get(url).text\n",
    "    soup = bs(source, 'lxml')\n",
    "    tbody = soup.find('tbody')\n",
    "    csv_file = open('team_odi.csv', 'w')\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(['Rank','Team', 'Matches', 'Points', 'Rating'])\n",
    "    a=0\n",
    "    m=0\n",
    "    n=1\n",
    "    k=0\n",
    "    rank=1\n",
    "    for i in tbody.find_all('span', class_='u-hide-phablet'):\n",
    "        team = i.text\n",
    "        if a == 0:\n",
    "            match = tbody.find('td', class_='rankings-block__banner--matches').text\n",
    "            points = tbody.find('td', class_='rankings-block__banner--points').text\n",
    "            rating = tbody.find('td', class_='rankings-block__banner--rating u-text-right').text.replace('\\n', '').strip()\n",
    "            writer.writerow([rank, team, match, points, rating])\n",
    "            rank=rank+1\n",
    "            a=a+1\n",
    "            continue\n",
    "        match = tbody.find_all('td',class_=\"table-body__cell u-center-text\")[m].text\n",
    "        points = tbody.find_all('td',class_=\"table-body__cell u-center-text\")[n].text\n",
    "        m=m+2\n",
    "        n=n+2\n",
    "        rating = tbody.find_all('td', class_=\"table-body__cell u-text-right rating\")[k].text\n",
    "        writer.writerow([rank,team, match, points, rating])\n",
    "        k=k+1\n",
    "        rank=rank+1\n",
    "        if k == 9:\n",
    "            break\n",
    "    csv_file.close()\n",
    "    df = pd.read_csv('team_odi.csv', encoding = 'unicode-escape')\n",
    "    print(df)\n",
    "    #Part 2\n",
    "    source = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting').text\n",
    "    soup = bs(source, 'lxml')\n",
    "    csv_file = open('women_batting.csv', 'w')\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(['Rank','Player','Team', 'Rating'])\n",
    "    table = soup.find('table', class_ = 'table rankings-table')\n",
    "    player = table.find('div', class_=\"rankings-block__banner--name-large\").text\n",
    "    team = table.find('div' ,class_=\"rankings-block__banner--nationality\").text.strip()\n",
    "    rating = table.find('div', class_=\"rankings-block__banner--rating\").text\n",
    "    rank = 1\n",
    "    writer.writerow([rank, player, team, rating])\n",
    "    for i, j, k  in zip(table.find_all('td', class_=\"table-body__cell rankings-table__name name\"),\n",
    "                    table.find_all('span', class_=\"table-body__logo-text\"),\n",
    "                    table.find_all('td' ,class_=\"table-body__cell rating\")):\n",
    "        player = i.text.strip()\n",
    "        team = j.text\n",
    "        rating = k.text\n",
    "        rank = rank+1\n",
    "        writer.writerow([rank, player, team, rating])\n",
    "        if rank == 10:\n",
    "            break\n",
    "    csv_file.close()\n",
    "    df=pd.read_csv('women_batting.csv', encoding = 'unicode-escape')\n",
    "    print(df)\n",
    "    #Part 3\n",
    "    source = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder').text\n",
    "    soup = bs(source, 'lxml')\n",
    "    table = soup.find('table', class_ = 'table rankings-table')\n",
    "    csv_file = open('womens_allrounder.csv', 'w')\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(['Rank','Player','Team', 'Rating'])\n",
    "    player = table.find('div', class_=\"rankings-block__banner--name-large\").text\n",
    "    team = table.find('div' ,class_=\"rankings-block__banner--nationality\").text.strip()\n",
    "    rating = table.find('div', class_=\"rankings-block__banner--rating\").text\n",
    "    rank = 1\n",
    "    writer.writerow([rank, player, team, rating])\n",
    "    for i, j, k  in zip(table.find_all('td', class_=\"table-body__cell rankings-table__name name\"),\n",
    "                    table.find_all('span', class_=\"table-body__logo-text\"),\n",
    "                    table.find_all('td' ,class_=\"table-body__cell rating\")):\n",
    "        player = i.text.strip()\n",
    "        team = j.text\n",
    "        rating = k.text\n",
    "        rank = rank+1\n",
    "        writer.writerow([rank, player, team, rating])\n",
    "        if rank == 10:\n",
    "            break\n",
    "    csv_file.close()\n",
    "    df = pd.read_csv('womens_allrounder.csv', encoding = 'unicode-escape')\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank          Team  Matches Points  Rating\n",
      "0     1     Australia       15  2,436     162\n",
      "1     2         India       15  1,812     121\n",
      "2     3       England       14  1,670     119\n",
      "3     4  South Africa       16  1,713     107\n",
      "4     5   New Zealand       15  1,384      92\n",
      "5     6   West Indies       12  1,025      85\n",
      "6     7      Pakistan       12    927      77\n",
      "7     8    Bangladesh        5    306      61\n",
      "8     9     Sri Lanka       11    519      47\n",
      "9    10       Ireland        2     25      13\n",
      "   Rank             Player Team  Rating\n",
      "0     1        Meg Lanning  AUS     749\n",
      "1     2    Stafanie Taylor   WI     746\n",
      "2     3       Alyssa Healy  AUS     741\n",
      "3     4    Smriti Mandhana  IND     732\n",
      "4     5  Amy Satterthwaite   NZ     723\n",
      "5     6     Tammy Beaumont  ENG     716\n",
      "6     7       Ellyse Perry  AUS     691\n",
      "7     8        Lizelle Lee   SA     690\n",
      "8     9    Laura Wolvaardt   SA     689\n",
      "9    10        Mithali Raj  IND     687\n",
      "   Rank            Player Team  Rating\n",
      "0     1      Ellyse Perry  AUS     460\n",
      "1     2   Stafanie Taylor   WI     410\n",
      "2     3    Marizanne Kapp   SA     389\n",
      "3     4     Deepti Sharma  IND     359\n",
      "4     5  Dane van Niekerk   SA     335\n",
      "5     6     Jess Jonassen  AUS     301\n",
      "6     7     Sophie Devine   NZ     289\n",
      "7     8    Natalie Sciver  ENG     273\n",
      "8     9     Shikha Pandey  IND     250\n",
      "9    10   Katherine Brunt  ENG     232\n"
     ]
    }
   ],
   "source": [
    "icc_women('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Mobile detail scraping - amazon.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amazon(url):\n",
    "    csv_file = open('mobiles1.csv', 'w', encoding = 'utf-8')\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"Phone\", \"Rating/5\",\"Votes\", \"Price\", 'Img_URL'])\n",
    "    source = requests.get(url).text\n",
    "    soup = bs(source, 'lxml')\n",
    "    for body in soup.find_all('span', class_ = \"celwidget slot=MAIN template=SEARCH_RESULTS widgetId=search-results\"):\n",
    "        name = body.find('span', class_=\"a-size-medium a-color-base a-text-normal\").text\n",
    "        rating = body.find('div', class_=\"a-row a-size-small\").text.split()[0] + '/5'\n",
    "        votes = body.find('div', class_=\"a-row a-size-small\").text.split()[5]\n",
    "        price = body.find('span', class_=\"a-offscreen\").text\n",
    "        img = body.find('img', class_=\"s-image\")['src']\n",
    "        writer.writerow([name, rating, votes, price, img])\n",
    "    csv_file.close()\n",
    "    df = pd.read_csv('mobiles1.csv', encoding = 'unicode-escape')\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Weather scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather(url):\n",
    "    source = requests.get(url).text\n",
    "    soup = bs(source, 'lxml')\n",
    "    csv_file = open('weather.csv', 'w')\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(['Period', 'Temperature', 'Short Description', 'Summary'])\n",
    "    for i in soup.find_all('div', class_=\"row row-odd row-forecast\"):\n",
    "        period = i.b.text\n",
    "        desc = i.find('div', class_ = 'col-sm-10 forecast-text').text\n",
    "        short_desc = desc.split(',')[0]\n",
    "        temp = re.findall('\\d+', desc)[0]\n",
    "        writer.writerow([period, temp, short_desc, desc])\n",
    "    csv_file.close()\n",
    "    df = pd.read_csv('weather.csv')\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Period  Temperature                            Short Description  \\\n",
      "0         Today            9  Patchy fog between 9am and 10am.  Otherwise   \n",
      "1      Thursday           10           Patchy fog before 10am.  Otherwise   \n",
      "2        Friday            8            Patchy fog before 8am.  Otherwise   \n",
      "3      Saturday            8            Patchy fog before 8am.  Otherwise   \n",
      "4        Sunday           65                                 Mostly sunny   \n",
      "5  M.L.King Day           68                                        Sunny   \n",
      "6       Tuesday           65                                        Sunny   \n",
      "\n",
      "                                             Summary  \n",
      "0  Patchy fog between 9am and 10am.  Otherwise, p...  \n",
      "1  Patchy fog before 10am.  Otherwise, mostly sun...  \n",
      "2  Patchy fog before 8am.  Otherwise, partly sunn...  \n",
      "3  Patchy fog before 8am.  Otherwise, mostly sunn...  \n",
      "4                 Mostly sunny, with a high near 65.  \n",
      "5                        Sunny, with a high near 68.  \n",
      "6                        Sunny, with a high near 65.  \n"
     ]
    }
   ],
   "source": [
    "weather('https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
